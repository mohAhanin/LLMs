{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install transformers>=4.40.1 accelerate>=0.27.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:26:12.063517Z","iopub.execute_input":"2025-06-11T08:26:12.063827Z","iopub.status.idle":"2025-06-11T08:26:15.551911Z","shell.execute_reply.started":"2025-06-11T08:26:12.063796Z","shell.execute_reply":"2025-06-11T08:26:15.550978Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\n\n# AutoModelForCausalLM: A class for loading causal language models\n# (models that generate text sequentially, like GPT).\n\n# AutoTokenizer: A class for loading the tokenizer associated with the model\n# (converts text to tokens and vice versa).\n\n\n\n# Load model and tokenizer\nmodel = AutoModelForCausalLM.from_pretrained(\n    \"microsoft/Phi-3-mini-4k-instruct\", # Model name on Hugging Face Hub\n    device_map=\"cpu\", # or Load model on GPU (CUDA)\n    torch_dtype=\"auto\", # Automatically select dtype (float16/float32)\n    trust_remote_code=True,  # Allow executing custom code from the model repo (if needed)\n)\n\ntokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n\n# The tokenizer is loaded from the same model repository and handles:\n# Text → Token conversion (for input).\n# Token → Text conversion (for output).","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:26:31.416105Z","iopub.execute_input":"2025-06-11T08:26:31.416418Z","iopub.status.idle":"2025-06-11T08:27:50.579287Z","shell.execute_reply.started":"2025-06-11T08:26:31.416391Z","shell.execute_reply":"2025-06-11T08:27:50.578523Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe6815280621454cabd009b0a1d6270b"}},"metadata":{}},{"name":"stderr","text":"2025-06-11 08:26:55.793514: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749630416.323110      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749630416.462272      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/16.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"680d22714d5b4087a0e22bce6c3a4007"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f7863548d34c28ac9da883d8f341ff"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e0374b14bcc42a89a345b27ef499085"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d32e8654d65f4abc838c5940c2c01d9b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e37659362dc642cdbbe272ad75ea110e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0726438567024812ad0cf1f1c0965921"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cf3636150c14e2b92834b28fd622639"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73edd58b30024a358ff7ec76e9c85598"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc82b31cbdf48e08d1349426d70cf59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c260f358f76d433dafc0006b19534176"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"151e6cf299364f03b2fe6cc414b92914"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# This code sets up a text-generation pipeline using Hugging Face's transformers library\nfrom transformers import pipeline\n\n# The pipeline() function is a high-level utility from Hugging Face\n# that simplifies inference tasks\n# (like text generation, translation, summarization, etc.).\n# Here, we're creating a text-generation pipeline.\n\n# Create a pipeline\ngenerator = pipeline(\n    \"text-generation\", # Task: Generate text\n    model=\"microsoft/Phi-3-mini-4k-instruct\", # Specify model by name\n    tokenizer=tokenizer, # No longer needed when specifying model by name\n    return_full_text=True, # Include input + generated text in output\n    max_new_tokens=100, # Max tokens to generate (longer = more output)\n    #Limits the response to 500 new tokens\n    do_sample=False  # Disable random sampling (deterministic output)\n#    temperature=0.7,        # 0.1–1.0: Lower = more deterministic\n)\n\n\n# return_full_text=True\n# If True: Output includes both the input prompt and generated text.\n# If False: Only returns the newly generated text.\n\n\n# do_sample=False\n# If False: Uses greedy decoding (always picks the most likely next token → deterministic output).\n# If True: Enables random sampling (creative but less predictable output, often used with temperature).\n\n\n# Deterministic vs. Random Outputs:\n# With do_sample=False, the same prompt will always produce the same output.\n# For creativity, set do_sample=True and add temperature=0.7 (higher = more random).","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:27:50.580614Z","iopub.execute_input":"2025-06-11T08:27:50.581373Z","iopub.status.idle":"2025-06-11T08:27:51.175919Z","shell.execute_reply.started":"2025-06-11T08:27:50.581346Z","shell.execute_reply":"2025-06-11T08:27:51.175254Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# The prompt (user input / query)\nmessages = [\n    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n]\n\n# role: Can be \"user\", \"assistant\", or \"system\" (for instructions).\n\n# Generate output\noutput = generator(messages)\nprint(output[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:28:03.346593Z","iopub.execute_input":"2025-06-11T08:28:03.346876Z","iopub.status.idle":"2025-06-11T08:28:05.954873Z","shell.execute_reply.started":"2025-06-11T08:28:03.346856Z","shell.execute_reply":"2025-06-11T08:28:05.954212Z"}},"outputs":[{"name":"stdout","text":" Why did the chicken join the band? Because it had the drumsticks!\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"how to spend the weekend?\"}\n]\n\n# Generate output\noutput = generator(messages)\nprint(output[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:31:03.040817Z","iopub.execute_input":"2025-06-11T08:31:03.041531Z","iopub.status.idle":"2025-06-11T08:31:23.996949Z","shell.execute_reply.started":"2025-06-11T08:31:03.041503Z","shell.execute_reply":"2025-06-11T08:31:23.996231Z"}},"outputs":[{"name":"stdout","text":" Spending a weekend can be a great opportunity to relax, recharge, and engage in activities that you enjoy. Here are some suggestions for how to spend your weekend:\n\n1. Plan ahead: Decide on a general theme or type of activity you'd like to do. This could be anything from outdoor adventures, cultural experiences, or simply relaxing at home.\n\n2. Outdoor activities: If the weather permits, consider going for a hike, a bike ride, or a picnic in a nearby park. You could also try a new sport or activity, like kayaking, rock climbing, or a nature walk.\n\n3. Explore your city: Visit a museum, art gallery, or historical site that you've never been to before. You could also take a walking tour of your city to learn more about its history and culture.\n\n4. Spend time with friends and family: Plan a get-together with friends or family members. You could have a potluck dinner, play board games, or watch a movie together.\n\n5. Self-care: Take some time for yourself to relax and recharge. This could include reading a book, taking a bubble bath, practicing yoga or meditation, or simply spending time in nature.\n\n6. Learn something new: Sign up for a class or workshop to learn a new skill or hobby. This could be anything from cooking, painting, or playing an instrument to learning a new language or taking a dance class.\n\n7. Volunteer: Spend your weekend giving back to your community by volunteering at a local charity or organization. This could be a great way to meet new people and make a positive impact.\n\n8. Travel: If you have the opportunity, consider taking a short trip to a nearby town or city. This could be a great way to explore new places and create lasting memories.\n\nRemember, the most important thing is to choose activities that you enjoy and that help you feel relaxed and rejuvenated. Have a great weekend!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"messages = [\n    {\"role\": \"user\", \"content\": \"what is your name? answer briefly\"}\n]\n\n# Generate output\noutput = generator(messages)\nprint(output[0][\"generated_text\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-11T08:32:36.885087Z","iopub.execute_input":"2025-06-11T08:32:36.885435Z","iopub.status.idle":"2025-06-11T08:32:37.706766Z","shell.execute_reply.started":"2025-06-11T08:32:36.885410Z","shell.execute_reply":"2025-06-11T08:32:37.705972Z"}},"outputs":[{"name":"stdout","text":" I am Phi, Microsoft's language model.\n","output_type":"stream"}],"execution_count":8}]}
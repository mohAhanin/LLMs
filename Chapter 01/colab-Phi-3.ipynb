{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNQDBMtROmymBlQkmZ4LfMi"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ecba5d021ac1476582bc124774748103":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb18bd975e9f4c59842bb3fbc230039a","IPY_MODEL_82f10ed69b5744afa34703c86bd8e77e","IPY_MODEL_529bbbb61a3c4a21b63af98c3192e9a4"],"layout":"IPY_MODEL_a502253d61c749348e109ce4c29e1856"}},"bb18bd975e9f4c59842bb3fbc230039a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4aa8c41ddd748d4aca45efbfd723d52","placeholder":"​","style":"IPY_MODEL_e637b2e60d5a4f8e844546ba1299536f","value":"Loading checkpoint shards: 100%"}},"82f10ed69b5744afa34703c86bd8e77e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d1e5a53f022b4433b26f77eb7bdcacb0","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f8b2a71efb264c8e9ddabe83e0f067e2","value":2}},"529bbbb61a3c4a21b63af98c3192e9a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8388763c74d4df08dcaea3a1c28c546","placeholder":"​","style":"IPY_MODEL_7392156e07a94570a32797e46d3fcd2f","value":" 2/2 [00:32&lt;00:00, 15.33s/it]"}},"a502253d61c749348e109ce4c29e1856":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4aa8c41ddd748d4aca45efbfd723d52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e637b2e60d5a4f8e844546ba1299536f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d1e5a53f022b4433b26f77eb7bdcacb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8b2a71efb264c8e9ddabe83e0f067e2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8388763c74d4df08dcaea3a1c28c546":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7392156e07a94570a32797e46d3fcd2f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["%%capture\n","!pip install transformers>=4.40.1 accelerate>=0.27.2"],"metadata":{"id":"DSOulkthE8L0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U transformers accelerate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AcpdfPPkKVs7","executionInfo":{"status":"ok","timestamp":1749631753527,"user_tz":-210,"elapsed":119533,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"outputId":"91f23524-cbb1-42e8-8846-082a55444431"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.32.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"]}]},{"cell_type":"code","source":["import transformers\n","print(transformers.__version__)  # Should be 4.41.x or newer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OdVfbAQJKtPb","executionInfo":{"status":"ok","timestamp":1749631759695,"user_tz":-210,"elapsed":6165,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"outputId":"4149dcd5-a65e-4a91-a98f-cb082aad678c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["4.52.4\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","# AutoModelForCausalLM: A class for loading causal language models\n","# (models that generate text sequentially, like GPT).\n","\n","# AutoTokenizer: A class for loading the tokenizer associated with the model\n","# (converts text to tokens and vice versa).\n","\n","\n","# Load model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained(\n","    \"microsoft/Phi-3-mini-4k-instruct\", # Model name on Hugging Face Hub\n","    device_map=\"cuda\", # Load model on GPU (CUDA)\n","    torch_dtype=\"auto\", # Automatically select dtype (float16/float32)\n","    trust_remote_code=False,  # Allow executing custom code from the model repo (if needed)\n",")\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-4k-instruct\")\n","\n","# The tokenizer is loaded from the same model repository and handles:\n","# Text → Token conversion (for input).\n","# Token → Text conversion (for output)."],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ecba5d021ac1476582bc124774748103","bb18bd975e9f4c59842bb3fbc230039a","82f10ed69b5744afa34703c86bd8e77e","529bbbb61a3c4a21b63af98c3192e9a4","a502253d61c749348e109ce4c29e1856","f4aa8c41ddd748d4aca45efbfd723d52","e637b2e60d5a4f8e844546ba1299536f","d1e5a53f022b4433b26f77eb7bdcacb0","f8b2a71efb264c8e9ddabe83e0f067e2","a8388763c74d4df08dcaea3a1c28c546","7392156e07a94570a32797e46d3fcd2f"]},"id":"IVBDfoRrHedG","executionInfo":{"status":"ok","timestamp":1749632022615,"user_tz":-210,"elapsed":34183,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"outputId":"90509210-bd36-4ba4-ae81-5c3e77f19aa2"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecba5d021ac1476582bc124774748103"}},"metadata":{}}]},{"cell_type":"code","source":["# This code sets up a text-generation pipeline using Hugging Face's transformers library\n","from transformers import pipeline\n","\n","# The pipeline() function is a high-level utility from Hugging Face\n","# that simplifies inference tasks\n","# (like text generation, translation, summarization, etc.).\n","# Here, we're creating a text-generation pipeline.\n","\n","# Create a pipeline\n","generator = pipeline(\n","    \"text-generation\", # Task: Generate text\n","    model=model, # Specify model by name\n","    tokenizer=tokenizer, # No longer needed when specifying model by name\n","    return_full_text=True, # Include input + generated text in output\n","    max_new_tokens=100, # Max tokens to generate (longer = more output)\n","    #Limits the response to 500 new tokens\n","    do_sample=False  # Disable random sampling (deterministic output)\n","#    temperature=0.7,        # 0.1–1.0: Lower = more deterministic\n",")\n","\n","\n","# return_full_text=True\n","# If True: Output includes both the input prompt and generated text.\n","# If False: Only returns the newly generated text.\n","\n","\n","# do_sample=False\n","# If False: Uses greedy decoding (always picks the most likely next token → deterministic output).\n","# If True: Enables random sampling (creative but less predictable output, often used with temperature).\n","\n","\n","# Deterministic vs. Random Outputs:\n","# With do_sample=False, the same prompt will always produce the same output.\n","# For creativity, set do_sample=True and add temperature=0.7 (higher = more random)."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XxZuCFHsJS41","outputId":"438d7a9d-b431-4000-f3c6-31849b95032d","executionInfo":{"status":"ok","timestamp":1749632029003,"user_tz":-210,"elapsed":117,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cuda\n","The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]}]},{"cell_type":"markdown","source":["The pipeline simplifies the process of generating text by handling all the underlying steps automatically."],"metadata":{"id":"DXT9DauvNvwD"}},{"cell_type":"code","source":["# The prompt (user input / query)\n","messages = [\n","    {\"role\": \"user\", \"content\": \"Create a funny joke about chickens.\"}\n","]\n","\n","# role: Can be \"user\", \"assistant\", or \"system\" (for instructions).\n","\n","# Generate output\n","output = generator(messages)\n","print(output[0][\"generated_text\"])"],"metadata":{"id":"8j44sXaRJOX1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1749632033797,"user_tz":-210,"elapsed":2733,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"outputId":"e8c50935-deab-4b6f-f222-432873bfe32b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[{'role': 'user', 'content': 'Create a funny joke about chickens.'}, {'role': 'assistant', 'content': ' Why did the chicken join the band? Because it had the drumsticks!'}]\n"]}]},{"cell_type":"code","source":["messages = [\n","    {\"role\": \"user\", \"content\": \"how to spend the weekend?\"}\n","]"],"metadata":{"id":"_GRop8xDJPK1","executionInfo":{"status":"ok","timestamp":1749632077719,"user_tz":-210,"elapsed":4,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Generate output\n","output = generator(messages)\n","print(output[0][\"generated_text\"])"],"metadata":{"id":"5dbEklYjLk3t","executionInfo":{"status":"ok","timestamp":1749632084615,"user_tz":-210,"elapsed":4752,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"822c4652-a8d2-4228-d4d8-c2e15fd109c3"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"]},{"output_type":"stream","name":"stdout","text":["[{'role': 'user', 'content': 'how to spend the weekend?'}, {'role': 'assistant', 'content': \" Spending a weekend can be a great opportunity to relax, recharge, and engage in activities that you enjoy. Here are some suggestions for how to spend your weekend:\\n\\n1. Plan ahead: Decide on a general theme or type of activity you'd like to do. This could be anything from outdoor adventures, cultural experiences, or simply relaxing at home.\\n\\n2. Outdoor activities: If the weather permits, consider going for a hi\"}]\n"]}]},{"cell_type":"code","source":["output[0][\"generated_text\"][0]['content']"],"metadata":{"id":"pJnFJrkaL90n","executionInfo":{"status":"ok","timestamp":1749632089125,"user_tz":-210,"elapsed":7,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"858136c7-75a8-4279-87ac-d1a6ef26197d"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'how to spend the weekend?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(output[0][\"generated_text\"][1]['content'])"],"metadata":{"id":"7PSdiILvORQm","executionInfo":{"status":"ok","timestamp":1749632090975,"user_tz":-210,"elapsed":6,"user":{"displayName":"Mohammadamin Ahanin","userId":"10543191548748598322"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"bdfbc247-7a21-443e-cf1f-12ed59aa67f7"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":[" Spending a weekend can be a great opportunity to relax, recharge, and engage in activities that you enjoy. Here are some suggestions for how to spend your weekend:\n","\n","1. Plan ahead: Decide on a general theme or type of activity you'd like to do. This could be anything from outdoor adventures, cultural experiences, or simply relaxing at home.\n","\n","2. Outdoor activities: If the weather permits, consider going for a hi\n"]}]},{"cell_type":"markdown","source":["Key Takeaways\n","\n","The Hugging Face Hub is a central repository for finding and downloading LLMs and other AI models.\n","\n","The Transformers library simplifies the process of loading and using LLMs, with utilities like pipeline for text generation.\n","\n","The Phi-3-mini model is a lightweight yet powerful generative model suitable for running on devices with limited resources.\n","\n","Text generation involves two main components: the model and the tokenizer. The tokenizer breaks input text into tokens, and the model generates text based on those tokens.\n","\n","The example demonstrates how to generate text using a simple prompt, resulting in a humorous output.\n","\n"],"metadata":{"id":"GyhhpN4tPcdr"}},{"cell_type":"code","source":[],"metadata":{"id":"91AjheIsPdJP"},"execution_count":null,"outputs":[]}]}